task: seq2seq
base_model: google/flan-t5-base
project_name: autotrain-seq2seq-hub-dataset
log: tensorboard
backend: local

data:
  path: samsum
  train_split: train
  valid_split: test
  column_mapping:
    text_column: dialogue
    target_column: summary

params:
  max_seq_length: 512
  epochs: 3
  batch_size: 4
  lr: 2e-5
  optimizer: adamw_torch
  scheduler: linear
  gradient_accumulation: 1
  mixed_precision: none

hub:
  username: ${HF_USERNAME}
  token: ${HF_TOKEN}
  push_to_hub: true