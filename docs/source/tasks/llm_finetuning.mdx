# 🤖 LLM Finetuning with Neural-Forge-Ai  

Neural-Forge-Ai makes **finetuning large language models (LLMs)** easier than ever!  
This guide walks you through everything you need to **train, optimize, and deploy custom LLMs.**  

---

## 🔥 Key Features  

✅ **Easy Data Formatting** – Supports **CSV & JSONL**  
✅ **Multiple Finetuning Approaches** – **SFT, DPO, ORPO, Reward Modeling**  
✅ **Built-in Chat Templates** – **Zephyr, ChatML, Tokenizer Config**  
✅ **Flexible Training** – **Local or Cloud (Hugging Face Spaces)**  
✅ **Optimized Hyperparameters** – **Best practices included**  

---

## 🏆 Supported Training Methods  

Neural-Forge-Ai supports multiple **specialized trainers**:  

| Trainer | Description |
|---------|-------------|
| `llm` | **Generic LLM trainer** |
| `llm-sft` | **Supervised Finetuning (SFT)** |
| `llm-reward` | **Reward Modeling Trainer** |
| `llm-dpo` | **Direct Preference Optimization (DPO)** |
| `llm-orpo` | **Optimal Reward Policy Optimization (ORPO)** |

---

## 📂 Data Preparation  

Neural-Forge-Ai **supports CSV & JSONL formats** (JSONL is preferred).  

### 🔹 Classic Text Generation  

Example **text generation dataset**:  

| text |
|------|
| Wikipedia is a free online encyclopedia |
| It is a collaborative project |
| That anyone can edit |
| Wikipedia is the largest reference work on the internet |

💡 Example dataset: **[stas/openwebtext-10k](https://huggingface.co/datasets/stas/openwebtext-10k)**  

✅ **Compatible Trainers**:  
- **SFT Trainer**  
- **Generic Trainer**  

---

### 🔹 Chatbots / QA / Code Generation  

✅ **Supports multi-turn conversations**  
✅ **`content` + `role`** structure  
✅ **JSONL preferred for automatic formatting**  

Example **chat dataset (single sample)**:  

```json
[
  {"content": "What is the capital of France?", "role": "user"},
  {"content": "The capital of France is Paris.", "role": "assistant"}
]
💡 Example dataset: HuggingFaceH4/no_robots

🔹 Using Chat Templates
Instead of manual formatting, Neural-Forge-Ai automates this with:

Chat Template	Usage
none (default)	Raw data
zephyr	Zephyr-style
chatml	OpenAI-style
tokenizer	Use model's tokenizer config
To enable automatic formatting, use the --chat-template parameter.

🔹 Advanced Custom Formatting
If you don't use --chat-template, manually format data like this:

 
<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nKnowledge Cutoff: 2023\nToday’s Date: 2024-03-10\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWho discovered gravity?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nSir Isaac Newton<|eot_id|>
💡 Example dataset: timdettmers/openassistant-guanaco

🏗️ Training with Neural-Forge-Ai
🏠 Local Training
Create a config.yaml file:

 
task: llm-orpo
base_model: meta-llama/Meta-Llama-3-8B-Instruct
project_name: neural-forge-llama3-8b-orpo
log: tensorboard
backend: local

data:
  path: argilla/distilabel-capybara-dpo-7k-binarized
  train_split: train
  valid_split: null
  chat_template: chatml
  column_mapping:
    text_column: chosen
    rejected_text_column: rejected
    prompt_text_column: prompt

params:
  block_size: 1024
  model_max_length: 8192
  max_prompt_length: 512
  epochs: 3
  batch_size: 2
  lr: 3e-5
  peft: true
  quantization: int4
  target_modules: all-linear
  padding: right
  optimizer: adamw_torch
  scheduler: linear
  gradient_accumulation: 4
  mixed_precision: fp16

hub:
  username: ${HF_USERNAME}
  token: ${HF_TOKEN}
  push_to_hub: true
To train the model:

bash
Copy
Edit
$ neural-forge-ai --config config.yaml
🔹 If using local training data, modify the data path:

 
data:
  path: path/to/training/file
  train_split: train
  valid_split: null
  chat_template: chatml
☁️ Training on Hugging Face Spaces
📍 Same process as local training!

💡 Example UI:



✅ Select model, dataset, and training parameters
✅ Set column mapping correctly
✅ Click Start Training

⚙️ Best Practices for LLM Fine-tuning
🔹 Memory Optimization
✅ Adjust block size for better memory efficiency
✅ Enable mixed precision training
✅ Use PEFT techniques for large models

🔹 Data Quality
✅ Clean & validate your training data
✅ Ensure balanced conversation samples
✅ Choose appropriate chat templates

🔹 Training Tips
✅ Start with small learning rates
✅ Monitor TensorBoard logs
✅ Validate model outputs frequently

🔗 Related Resources
🔗 Neural-Forge-Ai Documentation
🔗 Example Finetuned Models
🔗 Training Datasets

📜 Parameter Reference
🏆 LLM Fine-tuning Parameters
[[nuraldoc]] trainers.clm.params.LLMTrainingParams

🔹 Task-Specific Parameters
Parameter	Description
block_size	Maximum sequence length (auto by default)
model_max_length	Max model input length per batch
max_prompt_length	Max prompt length (for orpo & dpo)
max_completion_length	Max completion length (for ORPO models)
🚨 Constraints to avoid errors:
❌ block_size > model_max_length
❌ max_prompt_length > block_size
❌ max_completion_length > block_size

🛠️ Advanced Trainer-Specific Parameters
Generic Trainer
 
--add-eos-token
--block-size 1024
--model-max-length 8192
SFT Trainer
 
--block-size 1024
--model-max-length 8192
Reward Trainer
 
--block-size 1024
--model-max-length 8192
DPO Trainer
 
--dpo-beta 0.1
--model-ref llama-3
--block-size 1024
--model-max-length 8192
--max-prompt-length 512
--max-completion-length 512
ORPO Trainer
 
--block-size 1024
--model-max-length 8192
--max-prompt-length 512
--max-completion-length 512
🎯 Why Choose Neural-Forge-Ai?
✅ No-Code & Low-Code Training – UI-based workflow & Python API
✅ Supports SFT, DPO, ORPO & Reward Modeling
✅ Optimized for GPUs – Faster training & inference
✅ Cloud & Local Training – Flexibility to train anywhere
✅ Seamless Hugging Face Integration

🚀 Start finetuning your LLM with Neural-Forge-Ai today!