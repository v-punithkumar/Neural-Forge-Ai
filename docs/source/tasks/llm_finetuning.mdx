# ğŸ¤– LLM Finetuning with Neural-Forge-Ai  

Neural-Forge-Ai makes **finetuning large language models (LLMs)** easier than ever!  
This guide walks you through everything you need to **train, optimize, and deploy custom LLMs.**  

---

## ğŸ”¥ Key Features  

âœ… **Easy Data Formatting** â€“ Supports **CSV & JSONL**  
âœ… **Multiple Finetuning Approaches** â€“ **SFT, DPO, ORPO, Reward Modeling**  
âœ… **Built-in Chat Templates** â€“ **Zephyr, ChatML, Tokenizer Config**  
âœ… **Flexible Training** â€“ **Local or Cloud (Hugging Face Spaces)**  
âœ… **Optimized Hyperparameters** â€“ **Best practices included**  

---

## ğŸ† Supported Training Methods  

Neural-Forge-Ai supports multiple **specialized trainers**:  

| Trainer | Description |
|---------|-------------|
| `llm` | **Generic LLM trainer** |
| `llm-sft` | **Supervised Finetuning (SFT)** |
| `llm-reward` | **Reward Modeling Trainer** |
| `llm-dpo` | **Direct Preference Optimization (DPO)** |
| `llm-orpo` | **Optimal Reward Policy Optimization (ORPO)** |

---

## ğŸ“‚ Data Preparation  

Neural-Forge-Ai **supports CSV & JSONL formats** (JSONL is preferred).  

### ğŸ”¹ Classic Text Generation  

Example **text generation dataset**:  

| text |
|------|
| Wikipedia is a free online encyclopedia |
| It is a collaborative project |
| That anyone can edit |
| Wikipedia is the largest reference work on the internet |

ğŸ’¡ Example dataset: **[stas/openwebtext-10k](https://huggingface.co/datasets/stas/openwebtext-10k)**  

âœ… **Compatible Trainers**:  
- **SFT Trainer**  
- **Generic Trainer**  

---

### ğŸ”¹ Chatbots / QA / Code Generation  

âœ… **Supports multi-turn conversations**  
âœ… **`content` + `role`** structure  
âœ… **JSONL preferred for automatic formatting**  

Example **chat dataset (single sample)**:  

```json
[
  {"content": "What is the capital of France?", "role": "user"},
  {"content": "The capital of France is Paris.", "role": "assistant"}
]
ğŸ’¡ Example dataset: HuggingFaceH4/no_robots

ğŸ”¹ Using Chat Templates
Instead of manual formatting, Neural-Forge-Ai automates this with:

Chat Template	Usage
none (default)	Raw data
zephyr	Zephyr-style
chatml	OpenAI-style
tokenizer	Use model's tokenizer config
To enable automatic formatting, use the --chat-template parameter.

ğŸ”¹ Advanced Custom Formatting
If you don't use --chat-template, manually format data like this:

 
<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nKnowledge Cutoff: 2023\nTodayâ€™s Date: 2024-03-10\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWho discovered gravity?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nSir Isaac Newton<|eot_id|>
ğŸ’¡ Example dataset: timdettmers/openassistant-guanaco

ğŸ—ï¸ Training with Neural-Forge-Ai
ğŸ  Local Training
Create a config.yaml file:

 
task: llm-orpo
base_model: meta-llama/Meta-Llama-3-8B-Instruct
project_name: neural-forge-llama3-8b-orpo
log: tensorboard
backend: local

data:
  path: argilla/distilabel-capybara-dpo-7k-binarized
  train_split: train
  valid_split: null
  chat_template: chatml
  column_mapping:
    text_column: chosen
    rejected_text_column: rejected
    prompt_text_column: prompt

params:
  block_size: 1024
  model_max_length: 8192
  max_prompt_length: 512
  epochs: 3
  batch_size: 2
  lr: 3e-5
  peft: true
  quantization: int4
  target_modules: all-linear
  padding: right
  optimizer: adamw_torch
  scheduler: linear
  gradient_accumulation: 4
  mixed_precision: fp16

hub:
  username: ${HF_USERNAME}
  token: ${HF_TOKEN}
  push_to_hub: true
To train the model:

bash
Copy
Edit
$ neural-forge-ai --config config.yaml
ğŸ”¹ If using local training data, modify the data path:

 
data:
  path: path/to/training/file
  train_split: train
  valid_split: null
  chat_template: chatml
â˜ï¸ Training on Hugging Face Spaces
ğŸ“ Same process as local training!

ğŸ’¡ Example UI:



âœ… Select model, dataset, and training parameters
âœ… Set column mapping correctly
âœ… Click Start Training

âš™ï¸ Best Practices for LLM Fine-tuning
ğŸ”¹ Memory Optimization
âœ… Adjust block size for better memory efficiency
âœ… Enable mixed precision training
âœ… Use PEFT techniques for large models

ğŸ”¹ Data Quality
âœ… Clean & validate your training data
âœ… Ensure balanced conversation samples
âœ… Choose appropriate chat templates

ğŸ”¹ Training Tips
âœ… Start with small learning rates
âœ… Monitor TensorBoard logs
âœ… Validate model outputs frequently

ğŸ”— Related Resources
ğŸ”— Neural-Forge-Ai Documentation
ğŸ”— Example Finetuned Models
ğŸ”— Training Datasets

ğŸ“œ Parameter Reference
ğŸ† LLM Fine-tuning Parameters
[[nuraldoc]] trainers.clm.params.LLMTrainingParams

ğŸ”¹ Task-Specific Parameters
Parameter	Description
block_size	Maximum sequence length (auto by default)
model_max_length	Max model input length per batch
max_prompt_length	Max prompt length (for orpo & dpo)
max_completion_length	Max completion length (for ORPO models)
ğŸš¨ Constraints to avoid errors:
âŒ block_size > model_max_length
âŒ max_prompt_length > block_size
âŒ max_completion_length > block_size

ğŸ› ï¸ Advanced Trainer-Specific Parameters
Generic Trainer
 
--add-eos-token
--block-size 1024
--model-max-length 8192
SFT Trainer
 
--block-size 1024
--model-max-length 8192
Reward Trainer
 
--block-size 1024
--model-max-length 8192
DPO Trainer
 
--dpo-beta 0.1
--model-ref llama-3
--block-size 1024
--model-max-length 8192
--max-prompt-length 512
--max-completion-length 512
ORPO Trainer
 
--block-size 1024
--model-max-length 8192
--max-prompt-length 512
--max-completion-length 512
ğŸ¯ Why Choose Neural-Forge-Ai?
âœ… No-Code & Low-Code Training â€“ UI-based workflow & Python API
âœ… Supports SFT, DPO, ORPO & Reward Modeling
âœ… Optimized for GPUs â€“ Faster training & inference
âœ… Cloud & Local Training â€“ Flexibility to train anywhere
âœ… Seamless Hugging Face Integration

ğŸš€ Start finetuning your LLM with Neural-Forge-Ai today!